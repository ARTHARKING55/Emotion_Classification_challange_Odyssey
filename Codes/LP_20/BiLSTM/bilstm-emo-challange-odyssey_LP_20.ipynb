{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f22c622",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:28:53.327257Z",
     "iopub.status.busy": "2024-02-18T08:28:53.326902Z",
     "iopub.status.idle": "2024-02-18T08:29:16.236520Z",
     "shell.execute_reply": "2024-02-18T08:29:16.235380Z"
    },
    "papermill": {
     "duration": 22.920158,
     "end_time": "2024-02-18T08:29:16.239017",
     "exception": false,
     "start_time": "2024-02-18T08:28:53.318859",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (1.11.4)\r\n",
      "Collecting scipy\r\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: numpy<1.29.0,>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from scipy) (1.24.4)\r\n",
      "Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: scipy\r\n",
      "  Attempting uninstall: scipy\r\n",
      "    Found existing installation: scipy 1.11.4\r\n",
      "    Uninstalling scipy-1.11.4:\r\n",
      "      Successfully uninstalled scipy-1.11.4\r\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "cuml 23.8.0 requires cupy-cuda11x>=12.0.0, which is not installed.\r\n",
      "cuml 23.8.0 requires dask==2023.7.1, but you have dask 2024.1.0 which is incompatible.\r\n",
      "cuml 23.8.0 requires distributed==2023.7.1, but you have distributed 2024.1.0 which is incompatible.\r\n",
      "libpysal 4.9.2 requires packaging>=22, but you have packaging 21.3 which is incompatible.\r\n",
      "libpysal 4.9.2 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "momepy 0.7.0 requires shapely>=2, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "spopt 0.6.0 requires shapely>=2.0.1, but you have shapely 1.8.5.post1 which is incompatible.\r\n",
      "tensorflowjs 4.16.0 requires packaging~=23.1, but you have packaging 21.3 which is incompatible.\r\n",
      "ydata-profiling 4.6.4 requires scipy<1.12,>=1.4.1, but you have scipy 1.12.0 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0mSuccessfully installed scipy-1.12.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5eea0b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:16.256513Z",
     "iopub.status.busy": "2024-02-18T08:29:16.255811Z",
     "iopub.status.idle": "2024-02-18T08:29:20.467390Z",
     "shell.execute_reply": "2024-02-18T08:29:20.466581Z"
    },
    "papermill": {
     "duration": 4.222447,
     "end_time": "2024-02-18T08:29:20.469772",
     "exception": false,
     "start_time": "2024-02-18T08:29:16.247325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import os, pathlib, glob, random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import scipy\n",
    "from scipy import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ace2282",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:20.486162Z",
     "iopub.status.busy": "2024-02-18T08:29:20.485433Z",
     "iopub.status.idle": "2024-02-18T08:29:20.540300Z",
     "shell.execute_reply": "2024-02-18T08:29:20.539442Z"
    },
    "papermill": {
     "duration": 0.065005,
     "end_time": "2024-02-18T08:29:20.542244",
     "exception": false,
     "start_time": "2024-02-18T08:29:20.477239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4b9ab95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:20.558000Z",
     "iopub.status.busy": "2024-02-18T08:29:20.557678Z",
     "iopub.status.idle": "2024-02-18T08:29:20.561675Z",
     "shell.execute_reply": "2024-02-18T08:29:20.560858Z"
    },
    "papermill": {
     "duration": 0.013842,
     "end_time": "2024-02-18T08:29:20.563480",
     "exception": false,
     "start_time": "2024-02-18T08:29:20.549638",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "output_nodes = 10\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e2af445",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:20.579162Z",
     "iopub.status.busy": "2024-02-18T08:29:20.578840Z",
     "iopub.status.idle": "2024-02-18T08:29:20.582906Z",
     "shell.execute_reply": "2024-02-18T08:29:20.582198Z"
    },
    "papermill": {
     "duration": 0.014063,
     "end_time": "2024-02-18T08:29:20.584800",
     "exception": false,
     "start_time": "2024-02-18T08:29:20.570737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_data_path = r\"/kaggle/input/emotion-challange-lfrcc/LFRCC/BP_Utthira/Train\"\n",
    "val_data_path = r\"/kaggle/input/emotion-challange-lfrcc/LFRCC/BP_Utthira/Val\"\n",
    "test_data_path = r\"/kaggle/input/emotion-challange-lfrcc/LFRCC/BP_Utthira/Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2e19e94",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:20.600801Z",
     "iopub.status.busy": "2024-02-18T08:29:20.600549Z",
     "iopub.status.idle": "2024-02-18T08:29:20.610608Z",
     "shell.execute_reply": "2024-02-18T08:29:20.609821Z"
    },
    "papermill": {
     "duration": 0.020336,
     "end_time": "2024-02-18T08:29:20.612518",
     "exception": false,
     "start_time": "2024-02-18T08:29:20.592182",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PtDataset(Dataset):\n",
    "    def __init__(self, directory):\n",
    "        self.directory = directory\n",
    "        self.classes = sorted(entry.name for entry in os.scandir(directory) if entry.is_dir())\n",
    "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
    "        self.files = []\n",
    "        for c in self.classes:\n",
    "            c_dir = os.path.join(directory, c)\n",
    "            c_files = [(os.path.join(c_dir, f), self.class_to_idx[c]) for f in os.listdir(c_dir)]\n",
    "            self.files.extend(c_files)\n",
    "        random.shuffle(self.files)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filepath, label = self.files[idx]\n",
    "        try:\n",
    "            mat_vals = scipy.io.loadmat(filepath)\n",
    "            data = mat_vals['final']\n",
    "            data = data.T\n",
    "            max_len=900\n",
    "            if (max_len > data.shape[0]):\n",
    "                pad_width = max_len - data.shape[0]\n",
    "                data = np.pad(data, pad_width=((0, pad_width),(0,0)), mode='constant')\n",
    "            else:\n",
    "                data = data[:max_len, :]\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading file {filepath}: {str(e)}\")\n",
    "            return None\n",
    "        return data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e340c127",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:20.628494Z",
     "iopub.status.busy": "2024-02-18T08:29:20.628213Z",
     "iopub.status.idle": "2024-02-18T08:29:22.960359Z",
     "shell.execute_reply": "2024-02-18T08:29:22.959527Z"
    },
    "papermill": {
     "duration": 2.342855,
     "end_time": "2024-02-18T08:29:22.962735",
     "exception": false,
     "start_time": "2024-02-18T08:29:20.619880",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset = PtDataset(train_data_path)\n",
    "val_dataset = PtDataset(val_data_path)\n",
    "test_dataset = PtDataset(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "40397c4a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:22.978918Z",
     "iopub.status.busy": "2024-02-18T08:29:22.978632Z",
     "iopub.status.idle": "2024-02-18T08:29:22.983448Z",
     "shell.execute_reply": "2024-02-18T08:29:22.982602Z"
    },
    "papermill": {
     "duration": 0.014769,
     "end_time": "2024-02-18T08:29:22.985270",
     "exception": false,
     "start_time": "2024-02-18T08:29:22.970501",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PtDataLoader(DataLoader):\n",
    "    def __init__(self, directory, batch_size, shuffle=True):\n",
    "        dataset = PtDataset(directory)\n",
    "        super().__init__(dataset, batch_size=batch_size, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6ba6a8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:23.001684Z",
     "iopub.status.busy": "2024-02-18T08:29:23.001416Z",
     "iopub.status.idle": "2024-02-18T08:29:23.240927Z",
     "shell.execute_reply": "2024-02-18T08:29:23.240116Z"
    },
    "papermill": {
     "duration": 0.250613,
     "end_time": "2024-02-18T08:29:23.243184",
     "exception": false,
     "start_time": "2024-02-18T08:29:22.992571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = PtDataLoader(directory=train_data_path, batch_size=batch_size)\n",
    "val_dataloader = PtDataLoader(directory=val_data_path, batch_size=batch_size)\n",
    "test_dataloader = PtDataLoader(directory=test_data_path, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c2cdbca6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:23.259464Z",
     "iopub.status.busy": "2024-02-18T08:29:23.259162Z",
     "iopub.status.idle": "2024-02-18T08:29:23.263299Z",
     "shell.execute_reply": "2024-02-18T08:29:23.262406Z"
    },
    "papermill": {
     "duration": 0.014338,
     "end_time": "2024-02-18T08:29:23.265211",
     "exception": false,
     "start_time": "2024-02-18T08:29:23.250873",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_count = len(train_dataset) \n",
    "val_count = len(val_dataset)\n",
    "test_count = len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ca124a5e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:23.280938Z",
     "iopub.status.busy": "2024-02-18T08:29:23.280672Z",
     "iopub.status.idle": "2024-02-18T08:29:23.284836Z",
     "shell.execute_reply": "2024-02-18T08:29:23.283990Z"
    },
    "papermill": {
     "duration": 0.014379,
     "end_time": "2024-02-18T08:29:23.286984",
     "exception": false,
     "start_time": "2024-02-18T08:29:23.272605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53386\n",
      "15341\n",
      "2347\n"
     ]
    }
   ],
   "source": [
    "print(train_count)\n",
    "print(val_count)\n",
    "print(test_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e6a3c1a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:23.302693Z",
     "iopub.status.busy": "2024-02-18T08:29:23.302417Z",
     "iopub.status.idle": "2024-02-18T08:29:23.310970Z",
     "shell.execute_reply": "2024-02-18T08:29:23.310099Z"
    },
    "papermill": {
     "duration": 0.018654,
     "end_time": "2024-02-18T08:29:23.312990",
     "exception": false,
     "start_time": "2024-02-18T08:29:23.294336",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "drop_amount = 0.255\n",
    "\n",
    "class BiLSTMClassifier(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(BiLSTMClassifier, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.dropout = nn.Dropout(p=drop_amount)\n",
    "        self.fc = nn.Linear(hidden_size*2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device=x.device, dtype=torch.double)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(device=x.device, dtype=torch.double)\n",
    "        out, _ = self.lstm(x, (h0, c0))\n",
    "        out = self.dropout(out)\n",
    "        # Extract the output of the last time step from both directions\n",
    "        last_hidden_state = torch.cat((out[:, -1, :self.hidden_size], out[:, 0, self.hidden_size:]), dim=1)\n",
    "        output = self.fc(last_hidden_state)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e68737e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:23.328838Z",
     "iopub.status.busy": "2024-02-18T08:29:23.328572Z",
     "iopub.status.idle": "2024-02-18T08:29:23.332490Z",
     "shell.execute_reply": "2024-02-18T08:29:23.331665Z"
    },
    "papermill": {
     "duration": 0.014095,
     "end_time": "2024-02-18T08:29:23.334354",
     "exception": false,
     "start_time": "2024-02-18T08:29:23.320259",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Parameter\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e658c85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:23.350218Z",
     "iopub.status.busy": "2024-02-18T08:29:23.349921Z",
     "iopub.status.idle": "2024-02-18T08:29:23.679945Z",
     "shell.execute_reply": "2024-02-18T08:29:23.679092Z"
    },
    "papermill": {
     "duration": 0.340406,
     "end_time": "2024-02-18T08:29:23.682019",
     "exception": false,
     "start_time": "2024-02-18T08:29:23.341613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTMClassifier(\n",
       "  (lstm): LSTM(20, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
       "  (dropout): Dropout(p=0.255, inplace=False)\n",
       "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the parameters\n",
    "input_size = 20\n",
    "hidden_size = 256\n",
    "num_layers = 2\n",
    "num_classes = 8\n",
    "\n",
    "model = BiLSTMClassifier(input_size, hidden_size, num_layers, num_classes)\n",
    "model.to(device, dtype=torch.double)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e3c1a55b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:23.698672Z",
     "iopub.status.busy": "2024-02-18T08:29:23.698391Z",
     "iopub.status.idle": "2024-02-18T08:29:23.702487Z",
     "shell.execute_reply": "2024-02-18T08:29:23.701725Z"
    },
    "papermill": {
     "duration": 0.01424,
     "end_time": "2024-02-18T08:29:23.704256",
     "exception": false,
     "start_time": "2024-02-18T08:29:23.690016",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04e6cb51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:23.720029Z",
     "iopub.status.busy": "2024-02-18T08:29:23.719784Z",
     "iopub.status.idle": "2024-02-18T08:29:26.072806Z",
     "shell.execute_reply": "2024-02-18T08:29:26.071816Z"
    },
    "papermill": {
     "duration": 2.363534,
     "end_time": "2024-02-18T08:29:26.075239",
     "exception": false,
     "start_time": "2024-02-18T08:29:23.711705",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2aa239a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:26.092126Z",
     "iopub.status.busy": "2024-02-18T08:29:26.091673Z",
     "iopub.status.idle": "2024-02-18T08:29:26.096502Z",
     "shell.execute_reply": "2024-02-18T08:29:26.095643Z"
    },
    "papermill": {
     "duration": 0.015321,
     "end_time": "2024-02-18T08:29:26.098549",
     "exception": false,
     "start_time": "2024-02-18T08:29:26.083228",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTMClassifier(\n",
      "  (lstm): LSTM(20, 256, num_layers=2, batch_first=True, bidirectional=True)\n",
      "  (dropout): Dropout(p=0.255, inplace=False)\n",
      "  (fc): Linear(in_features=512, out_features=8, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0188f66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T08:29:26.114785Z",
     "iopub.status.busy": "2024-02-18T08:29:26.114493Z",
     "iopub.status.idle": "2024-02-18T16:48:13.392702Z",
     "shell.execute_reply": "2024-02-18T16:48:13.391692Z"
    },
    "papermill": {
     "duration": 29927.299311,
     "end_time": "2024-02-18T16:48:13.405283",
     "exception": false,
     "start_time": "2024-02-18T08:29:26.105972",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch : 1/40   Train Loss : tensor(1.5285, dtype=torch.float64)   Train Accuracy : 0.4682875660285468   Test Accuracy : 0.3694022553940421\n",
      "Epoch : 2/40   Train Loss : tensor(1.5126, dtype=torch.float64)   Train Accuracy : 0.4703854943243547   Test Accuracy : 0.3740955609151946\n",
      "Epoch : 3/40   Train Loss : tensor(1.4977, dtype=torch.float64)   Train Accuracy : 0.47291424718090885   Test Accuracy : 0.3763770288768659\n",
      "Epoch : 4/40   Train Loss : tensor(1.4813, dtype=torch.float64)   Train Accuracy : 0.4815682014011164   Test Accuracy : 0.37200964735023795\n",
      "Epoch : 5/40   Train Loss : tensor(1.4721, dtype=torch.float64)   Train Accuracy : 0.4839471022365414   Test Accuracy : 0.38387328075092886\n",
      "Epoch : 6/40   Train Loss : tensor(1.4704, dtype=torch.float64)   Train Accuracy : 0.4884051998651332   Test Accuracy : 0.3700541033830911\n",
      "Epoch : 7/40   Train Loss : tensor(1.4579, dtype=torch.float64)   Train Accuracy : 0.49113999925073987   Test Accuracy : 0.3768333224692002\n",
      "Epoch : 8/40   Train Loss : tensor(1.4514, dtype=torch.float64)   Train Accuracy : 0.49232008391713183   Test Accuracy : 0.37911479043087154\n",
      "Epoch : 9/40   Train Loss : tensor(1.4437, dtype=torch.float64)   Train Accuracy : 0.4975461731540104   Test Accuracy : 0.3778762792516785\n",
      "Epoch : 10/40   Train Loss : tensor(1.4327, dtype=torch.float64)   Train Accuracy : 0.5025474843591953   Test Accuracy : 0.3849814223323121\n",
      "Epoch : 11/40   Train Loss : tensor(1.4215, dtype=torch.float64)   Train Accuracy : 0.5049263851946203   Test Accuracy : 0.3877843686852226\n",
      "Epoch : 12/40   Train Loss : tensor(1.4105, dtype=torch.float64)   Train Accuracy : 0.5101337429288577   Test Accuracy : 0.3964539469395737\n",
      "Epoch : 13/40   Train Loss : tensor(1.3949, dtype=torch.float64)   Train Accuracy : 0.5148728130970667   Test Accuracy : 0.39893096929795974\n",
      "Epoch : 14/40   Train Loss : tensor(1.3777, dtype=torch.float64)   Train Accuracy : 0.5194245682388641   Test Accuracy : 0.3978880125154814\n",
      "Epoch : 15/40   Train Loss : tensor(1.3574, dtype=torch.float64)   Train Accuracy : 0.5256808901210055   Test Accuracy : 0.396258392542859\n",
      "Epoch : 16/40   Train Loss : tensor(1.3326, dtype=torch.float64)   Train Accuracy : 0.5326302776008691   Test Accuracy : 0.3929339677987093\n",
      "Epoch : 17/40   Train Loss : tensor(1.3081, dtype=torch.float64)   Train Accuracy : 0.5414902783501292   Test Accuracy : 0.406231666775308\n",
      "Epoch : 18/40   Train Loss : tensor(1.2780, dtype=torch.float64)   Train Accuracy : 0.5497883340201551   Test Accuracy : 0.3960628381461443\n",
      "Epoch : 19/40   Train Loss : tensor(1.2477, dtype=torch.float64)   Train Accuracy : 0.5613456711497397   Test Accuracy : 0.3990613388957695\n",
      "Epoch : 20/40   Train Loss : tensor(1.2094, dtype=torch.float64)   Train Accuracy : 0.5755441501517252   Test Accuracy : 0.39110879342937227\n",
      "Epoch : 21/40   Train Loss : tensor(1.1755, dtype=torch.float64)   Train Accuracy : 0.58727007080508   Test Accuracy : 0.38947917345674987\n",
      "Epoch : 22/40   Train Loss : tensor(1.1374, dtype=torch.float64)   Train Accuracy : 0.5997827145693627   Test Accuracy : 0.37865849683853725\n",
      "Epoch : 23/40   Train Loss : tensor(1.0959, dtype=torch.float64)   Train Accuracy : 0.6131008129472146   Test Accuracy : 0.37605110488234145\n",
      "Epoch : 24/40   Train Loss : tensor(1.0616, dtype=torch.float64)   Train Accuracy : 0.6283669875997453   Test Accuracy : 0.3709666905677596\n",
      "Epoch : 25/40   Train Loss : tensor(1.0193, dtype=torch.float64)   Train Accuracy : 0.642996291162477   Test Accuracy : 0.380679225604589\n",
      "Epoch : 26/40   Train Loss : tensor(0.9754, dtype=torch.float64)   Train Accuracy : 0.6585621698572659   Test Accuracy : 0.3572778827977316\n",
      "Epoch : 27/40   Train Loss : tensor(0.9420, dtype=torch.float64)   Train Accuracy : 0.670981156108343   Test Accuracy : 0.3697281793885666\n",
      "Epoch : 28/40   Train Loss : tensor(0.9080, dtype=torch.float64)   Train Accuracy : 0.6827820027722624   Test Accuracy : 0.3669252330356561\n",
      "Epoch : 29/40   Train Loss : tensor(0.8776, dtype=torch.float64)   Train Accuracy : 0.6948450904731578   Test Accuracy : 0.35890750277035394\n",
      "Epoch : 30/40   Train Loss : tensor(0.8427, dtype=torch.float64)   Train Accuracy : 0.7065335481212303   Test Accuracy : 0.35955935075940293\n",
      "Epoch : 31/40   Train Loss : tensor(0.8070, dtype=torch.float64)   Train Accuracy : 0.7185591728168433   Test Accuracy : 0.344566847011277\n",
      "Epoch : 32/40   Train Loss : tensor(0.7776, dtype=torch.float64)   Train Accuracy : 0.728149702169108   Test Accuracy : 0.3540186428524868\n",
      "Epoch : 33/40   Train Loss : tensor(0.7503, dtype=torch.float64)   Train Accuracy : 0.7384520286217361   Test Accuracy : 0.3512156964995763\n",
      "Epoch : 34/40   Train Loss : tensor(0.7248, dtype=torch.float64)   Train Accuracy : 0.7486419660585172   Test Accuracy : 0.3456098037937553\n",
      "Epoch : 35/40   Train Loss : tensor(0.6870, dtype=torch.float64)   Train Accuracy : 0.7614917768703405   Test Accuracy : 0.3497164461247637\n",
      "Epoch : 36/40   Train Loss : tensor(0.6689, dtype=torch.float64)   Train Accuracy : 0.7686659423818979   Test Accuracy : 0.35062903330943224\n",
      "Epoch : 37/40   Train Loss : tensor(0.6473, dtype=torch.float64)   Train Accuracy : 0.7748660697561158   Test Accuracy : 0.33922169350107556\n",
      "Epoch : 38/40   Train Loss : tensor(0.6259, dtype=torch.float64)   Train Accuracy : 0.7828456898812423   Test Accuracy : 0.3372009647350238\n",
      "Epoch : 39/40   Train Loss : tensor(0.5922, dtype=torch.float64)   Train Accuracy : 0.7955456486719364   Test Accuracy : 0.34046020468026855\n",
      "Epoch : 40/40   Train Loss : tensor(0.5879, dtype=torch.float64)   Train Accuracy : 0.7973813359307683   Test Accuracy : 0.3332898768007301\n",
      "0.406231666775308\n",
      "Finished Training and Testing\n"
     ]
    }
   ],
   "source": [
    "#Model training and testing \n",
    "n_total_steps = len(train_dataloader) # n_total_steps * batch size will give total number of training files (consider that last batch may not be fully filled)\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "val_accuracy_list = []\n",
    "max_acc=0\n",
    "num_epochs = 40\n",
    "pred_labels =[]\n",
    "act_labels = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    \n",
    "    #Evaluation and training on training dataset\n",
    "    model.train()\n",
    "    train_accuracy=0.0\n",
    "    train_loss=0.0\n",
    "    \n",
    "    for batch_idx, (images,labels) in enumerate(train_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        ##images = images.unsqueeze(1)\n",
    "        optimizer.zero_grad()\n",
    "        outputs=model(images)\n",
    "        loss=loss_function(outputs,labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        \n",
    "        train_loss+= loss.cpu().data*images.size(0)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        \n",
    "        train_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "    train_accuracy=train_accuracy/train_count\n",
    "    train_loss=train_loss/train_count\n",
    "    \n",
    "    train_accuracy_list.append(train_accuracy)\n",
    "    train_loss_list.append(train_loss)\n",
    "\n",
    "    \n",
    "    # Validation on Validation dataset\n",
    "    model.eval()\n",
    "    val_accuracy=0.0\n",
    "    pred = []\n",
    "    lab = []\n",
    "    \n",
    "    for i, (images,labels) in enumerate(val_dataloader):\n",
    "        if torch.cuda.is_available():\n",
    "            images=Variable(images.cuda())\n",
    "            labels=Variable(labels.cuda())\n",
    "        ##images = images.unsqueeze(1) \n",
    "#         print(i,images.shape)\n",
    "        outputs=model(images)\n",
    "        _,prediction=torch.max(outputs.data,1)\n",
    "        val_accuracy+=int(torch.sum(prediction==labels.data))\n",
    "        \n",
    "        pred.extend(prediction.tolist())\n",
    "        lab.extend(labels.tolist())\n",
    "    \n",
    "    val_accuracy=val_accuracy/val_count\n",
    "    val_accuracy_list.append(val_accuracy)\n",
    "    if max_acc < val_accuracy:\n",
    "        max_acc = val_accuracy\n",
    "        pred_labels = pred\n",
    "        actual_labels = lab\n",
    "        max_acc = val_accuracy\n",
    "        torch.save(model,\"best_accuracy_model_BiLSTM.pth\")\n",
    "    print('Epoch : '+str(epoch+1)+'/'+str(num_epochs)+'   Train Loss : '+str(train_loss)+'   Train Accuracy : '+str(train_accuracy)+'   Test Accuracy : '+str(val_accuracy))\n",
    "print(max_acc)   \n",
    "print('Finished Training and Testing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "716900cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-18T16:48:13.427753Z",
     "iopub.status.busy": "2024-02-18T16:48:13.427444Z",
     "iopub.status.idle": "2024-02-18T16:48:14.338153Z",
     "shell.execute_reply": "2024-02-18T16:48:14.336980Z"
    },
    "papermill": {
     "duration": 0.923952,
     "end_time": "2024-02-18T16:48:14.339804",
     "exception": true,
     "start_time": "2024-02-18T16:48:13.415852",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'PtDataset' object has no attribute 'samples'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 40\u001b[0m\n\u001b[1;32m     37\u001b[0m _, prediction \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     39\u001b[0m \u001b[38;5;66;03m# Extract filenames from test dataset\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m batch_filenames \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msamples\u001b[49m[i][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Append filename and predicted label to the list\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename, pred_label \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(batch_filenames, prediction):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Assuming you have a mapping from label index to class name\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m# Replace label_to_class with your actual mapping\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'PtDataset' object has no attribute 'samples'"
     ]
    }
   ],
   "source": [
    "# best_model = torch.load(\"best_accuracy_model_BiLSTM.pth\")\n",
    "# best_model.eval()\n",
    "# testing_accuracy = 0.0\n",
    "# pred_labels = []\n",
    "# act_labels = []\n",
    "# for i, (images, labels) in enumerate(test_dataloader):\n",
    "#     if torch.cuda.is_available():\n",
    "#         images = Variable(images.cuda())\n",
    "#         labels = Variable(labels.cuda())\n",
    "    \n",
    "#     outputs = best_model(images)\n",
    "#     _, prediction = torch.max(outputs.data, 1)\n",
    "    \n",
    "#     testing_accuracy += int(torch.sum(prediction == labels.data))\n",
    "    \n",
    "#     pred_labels.extend(prediction.tolist())\n",
    "#     act_labels.extend(labels.tolist())\n",
    "\n",
    "# testing_accuracy = testing_accuracy / len(test_dataloader.dataset)\n",
    "# print(\"testing Accuracy:\", testing_accuracy)\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "# Assuming you have defined your test_dataloader previously\n",
    "\n",
    "best_model = torch.load(\"best_accuracy_model_BiLSTM.pth\")\n",
    "best_model.eval()\n",
    "\n",
    "# Initialize lists to store filenames and predicted labels\n",
    "file_predictions = []\n",
    "\n",
    "for i, (images, _) in enumerate(test_dataloader):  # Assuming you don't have access to actual labels\n",
    "    if torch.cuda.is_available():\n",
    "        images = Variable(images.cuda())\n",
    "\n",
    "    outputs = best_model(images)\n",
    "    _, prediction = torch.max(outputs.data, 1)\n",
    "    \n",
    "    # Extract filenames from test dataset\n",
    "    batch_filenames = test_dataloader.dataset.samples[i][0]\n",
    "    \n",
    "    # Append filename and predicted label to the list\n",
    "    for filename, pred_label in zip(batch_filenames, prediction):\n",
    "        # Assuming you have a mapping from label index to class name\n",
    "        # Replace label_to_class with your actual mapping\n",
    "        class_name = label_to_class[pred_label.item()]\n",
    "        file_predictions.append((filename, class_name))\n",
    "\n",
    "# Save the filename and predicted label pairs to a text file\n",
    "with open(\"predicted_labels.txt\", \"w\") as f:\n",
    "    for filename, pred_class in file_predictions:\n",
    "        f.write(f\"{filename}, {pred_class}\\n\")\n",
    "\n",
    "print(\"Prediction results saved to predicted_labels.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbea6ac2",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.plot(train_accuracy_list, label='Train Accuracy')\n",
    "plt.plot(test_accuracy_list, label='Test Accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Train and Test Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig(\"TrainVsTest.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54ba391",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-21T04:42:55.134167Z",
     "iopub.status.busy": "2023-08-21T04:42:55.133212Z",
     "iopub.status.idle": "2023-08-21T04:42:56.492342Z",
     "shell.execute_reply": "2023-08-21T04:42:56.491385Z",
     "shell.execute_reply.started": "2023-08-21T04:42:55.134124Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Calculate the confusion matrix\n",
    "import seaborn as sns\n",
    "conf_mat = confusion_matrix(actual_labels, pred_labels)\n",
    "# Plot confusion matrix heat map\n",
    "sns.heatmap(conf_mat, cmap=\"flare\",annot=True, fmt = \"g\", \n",
    "            cbar_kws={\"label\":\"color bar\"},\n",
    "            xticklabels=train_dataset.classes,\n",
    "            yticklabels=train_dataset.classes)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.savefig(\"ConfusionMatrix.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 4456617,
     "sourceId": 7645627,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30648,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 29965.424609,
   "end_time": "2024-02-18T16:48:16.031189",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-18T08:28:50.606580",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
